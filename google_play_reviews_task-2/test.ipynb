{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                App  \\\n",
       "0            10 Best Foods for You   \n",
       "1            10 Best Foods for You   \n",
       "2            10 Best Foods for You   \n",
       "3            10 Best Foods for You   \n",
       "4            10 Best Foods for You   \n",
       "5            10 Best Foods for You   \n",
       "6            10 Best Foods for You   \n",
       "7            10 Best Foods for You   \n",
       "8            10 Best Foods for You   \n",
       "9            10 Best Foods for You   \n",
       "10           10 Best Foods for You   \n",
       "11           10 Best Foods for You   \n",
       "12           10 Best Foods for You   \n",
       "13           10 Best Foods for You   \n",
       "14           10 Best Foods for You   \n",
       "15           10 Best Foods for You   \n",
       "16           10 Best Foods for You   \n",
       "17           10 Best Foods for You   \n",
       "18           10 Best Foods for You   \n",
       "19           10 Best Foods for You   \n",
       "20           10 Best Foods for You   \n",
       "21           10 Best Foods for You   \n",
       "22           10 Best Foods for You   \n",
       "23           10 Best Foods for You   \n",
       "24           10 Best Foods for You   \n",
       "25           10 Best Foods for You   \n",
       "26           10 Best Foods for You   \n",
       "27           10 Best Foods for You   \n",
       "28           10 Best Foods for You   \n",
       "29           10 Best Foods for You   \n",
       "...                            ...   \n",
       "64265  Houzz Interior Design Ideas   \n",
       "64266  Houzz Interior Design Ideas   \n",
       "64267  Houzz Interior Design Ideas   \n",
       "64268  Houzz Interior Design Ideas   \n",
       "64269  Houzz Interior Design Ideas   \n",
       "64270  Houzz Interior Design Ideas   \n",
       "64271  Houzz Interior Design Ideas   \n",
       "64272  Houzz Interior Design Ideas   \n",
       "64273  Houzz Interior Design Ideas   \n",
       "64274  Houzz Interior Design Ideas   \n",
       "64275  Houzz Interior Design Ideas   \n",
       "64276  Houzz Interior Design Ideas   \n",
       "64277  Houzz Interior Design Ideas   \n",
       "64278  Houzz Interior Design Ideas   \n",
       "64279  Houzz Interior Design Ideas   \n",
       "64280  Houzz Interior Design Ideas   \n",
       "64281  Houzz Interior Design Ideas   \n",
       "64282  Houzz Interior Design Ideas   \n",
       "64283  Houzz Interior Design Ideas   \n",
       "64284  Houzz Interior Design Ideas   \n",
       "64285  Houzz Interior Design Ideas   \n",
       "64286  Houzz Interior Design Ideas   \n",
       "64287  Houzz Interior Design Ideas   \n",
       "64288  Houzz Interior Design Ideas   \n",
       "64289  Houzz Interior Design Ideas   \n",
       "64290  Houzz Interior Design Ideas   \n",
       "64291  Houzz Interior Design Ideas   \n",
       "64292  Houzz Interior Design Ideas   \n",
       "64293  Houzz Interior Design Ideas   \n",
       "64294  Houzz Interior Design Ideas   \n",
       "\n",
       "                                       Translated_Review Sentiment  \\\n",
       "0      I like eat delicious food. That's I'm cooking ...  Positive   \n",
       "1        This help eating healthy exercise regular basis  Positive   \n",
       "2                                                    NaN       NaN   \n",
       "3             Works great especially going grocery store  Positive   \n",
       "4                                           Best idea us  Positive   \n",
       "5                                               Best way  Positive   \n",
       "6                                                Amazing  Positive   \n",
       "7                                                    NaN       NaN   \n",
       "8                                   Looking forward app,   Neutral   \n",
       "9                  It helpful site ! It help foods get !   Neutral   \n",
       "10                                             good you.  Positive   \n",
       "11     Useful information The amount spelling errors ...  Positive   \n",
       "12     Thank you! Great app!! Add arthritis, eyes, im...  Positive   \n",
       "13     Greatest ever Completely awesome maintain heal...  Positive   \n",
       "14     Good health...... Good health first priority.....  Positive   \n",
       "15                                                   NaN       NaN   \n",
       "16     Health It's important world either life . thin...  Positive   \n",
       "17     Mrs sunita bhati I thankful developers,to make...  Positive   \n",
       "18     Very Useful in diabetes age 30. I need control...  Positive   \n",
       "19                                    One greatest apps.  Positive   \n",
       "20                                             good nice  Positive   \n",
       "21                                 Healthy Really helped  Positive   \n",
       "22                                            God health   Neutral   \n",
       "23     HEALTH SHOULD ALWAYS BE TOP PRIORITY. !!. ON M...  Positive   \n",
       "24                                 An excellent A useful  Positive   \n",
       "25                     I found lot wealth form health...   Neutral   \n",
       "26                            Because I found important.  Positive   \n",
       "27                                        Healthy Eating  Positive   \n",
       "28                                 Very good Simply good  Positive   \n",
       "29                                           On test....   Neutral   \n",
       "...                                                  ...       ...   \n",
       "64265                                                NaN       NaN   \n",
       "64266                                                NaN       NaN   \n",
       "64267                                                NaN       NaN   \n",
       "64268                                                NaN       NaN   \n",
       "64269                                                NaN       NaN   \n",
       "64270                                                NaN       NaN   \n",
       "64271                                                NaN       NaN   \n",
       "64272                                                NaN       NaN   \n",
       "64273                                                NaN       NaN   \n",
       "64274                                                NaN       NaN   \n",
       "64275                                                NaN       NaN   \n",
       "64276                                                NaN       NaN   \n",
       "64277                                                NaN       NaN   \n",
       "64278                                                NaN       NaN   \n",
       "64279                                                NaN       NaN   \n",
       "64280                                                NaN       NaN   \n",
       "64281                                                NaN       NaN   \n",
       "64282                                                NaN       NaN   \n",
       "64283                                                NaN       NaN   \n",
       "64284                                                NaN       NaN   \n",
       "64285                                                NaN       NaN   \n",
       "64286                                                NaN       NaN   \n",
       "64287                                                NaN       NaN   \n",
       "64288                                                NaN       NaN   \n",
       "64289                                                NaN       NaN   \n",
       "64290                                                NaN       NaN   \n",
       "64291                                                NaN       NaN   \n",
       "64292                                                NaN       NaN   \n",
       "64293                                                NaN       NaN   \n",
       "64294                                                NaN       NaN   \n",
       "\n",
       "       Sentiment_Polarity  Sentiment_Subjectivity  \n",
       "0                1.000000                0.533333  \n",
       "1                0.250000                0.288462  \n",
       "2                     NaN                     NaN  \n",
       "3                0.400000                0.875000  \n",
       "4                1.000000                0.300000  \n",
       "5                1.000000                0.300000  \n",
       "6                0.600000                0.900000  \n",
       "7                     NaN                     NaN  \n",
       "8                0.000000                0.000000  \n",
       "9                0.000000                0.000000  \n",
       "10               0.700000                0.600000  \n",
       "11               0.200000                0.100000  \n",
       "12               0.750000                0.875000  \n",
       "13               0.992188                0.866667  \n",
       "14               0.550000                0.511111  \n",
       "15                    NaN                     NaN  \n",
       "16               0.450000                1.000000  \n",
       "17               0.600000                0.666667  \n",
       "18               0.295000                0.100000  \n",
       "19               1.000000                1.000000  \n",
       "20               0.650000                0.800000  \n",
       "21               0.350000                0.350000  \n",
       "22               0.000000                0.000000  \n",
       "23               0.781250                0.500000  \n",
       "24               0.650000                0.500000  \n",
       "25               0.000000                0.000000  \n",
       "26               0.400000                1.000000  \n",
       "27               0.500000                0.500000  \n",
       "28               0.805000                0.690000  \n",
       "29               0.000000                0.000000  \n",
       "...                   ...                     ...  \n",
       "64265                 NaN                     NaN  \n",
       "64266                 NaN                     NaN  \n",
       "64267                 NaN                     NaN  \n",
       "64268                 NaN                     NaN  \n",
       "64269                 NaN                     NaN  \n",
       "64270                 NaN                     NaN  \n",
       "64271                 NaN                     NaN  \n",
       "64272                 NaN                     NaN  \n",
       "64273                 NaN                     NaN  \n",
       "64274                 NaN                     NaN  \n",
       "64275                 NaN                     NaN  \n",
       "64276                 NaN                     NaN  \n",
       "64277                 NaN                     NaN  \n",
       "64278                 NaN                     NaN  \n",
       "64279                 NaN                     NaN  \n",
       "64280                 NaN                     NaN  \n",
       "64281                 NaN                     NaN  \n",
       "64282                 NaN                     NaN  \n",
       "64283                 NaN                     NaN  \n",
       "64284                 NaN                     NaN  \n",
       "64285                 NaN                     NaN  \n",
       "64286                 NaN                     NaN  \n",
       "64287                 NaN                     NaN  \n",
       "64288                 NaN                     NaN  \n",
       "64289                 NaN                     NaN  \n",
       "64290                 NaN                     NaN  \n",
       "64291                 NaN                     NaN  \n",
       "64292                 NaN                     NaN  \n",
       "64293                 NaN                     NaN  \n",
       "64294                 NaN                     NaN  \n",
       "\n",
       "[64295 rows x 5 columns]>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import warnings\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "import re\n",
    "import plotly\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2, SelectKBest, SelectPercentile\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "#Read data from file\n",
    "path_to_file=\"./googleplaystore_user_reviews.csv\"\n",
    "data = pd.read_csv(path_to_file, encoding=\"utf-8\")\n",
    "data.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64295, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neded fields: Translated_Review abd Sentiment\n",
    "data = data[[\"Translated_Review\", \"Sentiment\"]]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27994, 2)\n"
     ]
    }
   ],
   "source": [
    "# dropping nan's and duplicates\n",
    "data = data.dropna()\n",
    "data = data.drop_duplicates()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetting indexes of dataframe rows\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Translated_Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[i, like, eat, delicious, food, that, s, i, m,...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[this, help, eating, healthy, exercise, regula...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[works, great, especially, going, grocery, store]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[best, idea, us]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[best, way]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[amazing]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[looking, forward, app]</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[it, helpful, site, it, help, foods, get]</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[good, you]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[useful, information, the, amount, spelling, e...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[thank, you, great, app, add, arthritis, eyes,...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Translated_Review Sentiment\n",
       "0   [i, like, eat, delicious, food, that, s, i, m,...  Positive\n",
       "1   [this, help, eating, healthy, exercise, regula...  Positive\n",
       "2   [works, great, especially, going, grocery, store]  Positive\n",
       "3                                    [best, idea, us]  Positive\n",
       "4                                         [best, way]  Positive\n",
       "5                                           [amazing]  Positive\n",
       "6                             [looking, forward, app]   Neutral\n",
       "7           [it, helpful, site, it, help, foods, get]   Neutral\n",
       "8                                         [good, you]  Positive\n",
       "9   [useful, information, the, amount, spelling, e...  Positive\n",
       "10  [thank, you, great, app, add, arthritis, eyes,...  Positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we need to remove all symbols from rows like: !@#$%^&*()...\n",
    "# I will write some function for that using a little of regexp\n",
    "\n",
    "def tokenize(text):\n",
    "    text = re.split('\\W+', text)\n",
    "    tokens = []\n",
    "    for word in text:\n",
    "        if word.isalpha():\n",
    "            tokens.append(word.lower())\n",
    "    return tokens\n",
    "\n",
    "data[\"Translated_Review\"] = data[\"Translated_Review\"].apply(lambda x: tokenize(x))\n",
    "data.loc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Translated_Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[like, eat, delicious, food, cooking, food, ca...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[help, eating, healthy, exercise, regular, basis]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[works, great, especially, going, grocery, store]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[best, idea, us]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[best, way]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[amazing]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[looking, forward, app]</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[helpful, site, help, foods, get]</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[good]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[useful, information, amount, spelling, errors...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[thank, great, app, add, arthritis, eyes, immu...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Translated_Review Sentiment\n",
       "0   [like, eat, delicious, food, cooking, food, ca...  Positive\n",
       "1   [help, eating, healthy, exercise, regular, basis]  Positive\n",
       "2   [works, great, especially, going, grocery, store]  Positive\n",
       "3                                    [best, idea, us]  Positive\n",
       "4                                         [best, way]  Positive\n",
       "5                                           [amazing]  Positive\n",
       "6                             [looking, forward, app]   Neutral\n",
       "7                   [helpful, site, help, foods, get]   Neutral\n",
       "8                                              [good]  Positive\n",
       "9   [useful, information, amount, spelling, errors...  Positive\n",
       "10  [thank, great, app, add, arthritis, eyes, immu...  Positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After that I will remove all stop words from Translated_Review column\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "def remove_stopwords(token_list):\n",
    "    return [word for word in token_list if word not in stopwords]\n",
    "\n",
    "data[\"Translated_Review\"] = data[\"Translated_Review\"].apply(lambda x: remove_stopwords(x))\n",
    "data.loc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Translated_Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[like, eat, delicious, food, cooking, food, ca...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[help, eating, healthy, exercise, regular, basis]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[work, great, especially, going, grocery, store]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[best, idea, u]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[best, way]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[amazing]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[looking, forward, app]</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[helpful, site, help, food, get]</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[good]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[useful, information, amount, spelling, error,...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[thank, great, app, add, arthritis, eye, immun...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Translated_Review Sentiment\n",
       "0   [like, eat, delicious, food, cooking, food, ca...  Positive\n",
       "1   [help, eating, healthy, exercise, regular, basis]  Positive\n",
       "2    [work, great, especially, going, grocery, store]  Positive\n",
       "3                                     [best, idea, u]  Positive\n",
       "4                                         [best, way]  Positive\n",
       "5                                           [amazing]  Positive\n",
       "6                             [looking, forward, app]   Neutral\n",
       "7                    [helpful, site, help, food, get]   Neutral\n",
       "8                                              [good]  Positive\n",
       "9   [useful, information, amount, spelling, error,...  Positive\n",
       "10  [thank, great, app, add, arthritis, eye, immun...  Positive"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making lemmatization of Translated_Review column\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(token_list):\n",
    "    return [lemmatizer.lemmatize(word) for word in token_list]\n",
    "\n",
    "data[\"Translated_Review\"] = data[\"Translated_Review\"].apply(lambda x: lemmatize(x))\n",
    "data.loc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Translated_Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like eat delicious food cooking food case best...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>help eating healthy exercise regular basis</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>work great especially going grocery store</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>best idea u</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>best way</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>amazing</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>looking forward app</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>helpful site help food get</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>good</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>useful information amount spelling error quest...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>thank great app add arthritis eye immunity kid...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Translated_Review Sentiment\n",
       "0   like eat delicious food cooking food case best...  Positive\n",
       "1          help eating healthy exercise regular basis  Positive\n",
       "2           work great especially going grocery store  Positive\n",
       "3                                         best idea u  Positive\n",
       "4                                            best way  Positive\n",
       "5                                             amazing  Positive\n",
       "6                                 looking forward app   Neutral\n",
       "7                          helpful site help food get   Neutral\n",
       "8                                                good  Positive\n",
       "9   useful information amount spelling error quest...  Positive\n",
       "10  thank great app add arthritis eye immunity kid...  Positive"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I think that the best transformer would be CountVectorizer, so we need to make our reviews string again\n",
    "\n",
    "def make_string_again(token_list):\n",
    "    return \" \".join(word for word in token_list)\n",
    "\n",
    "data[\"Translated_Review\"] = data[\"Translated_Review\"].apply(lambda x: make_string_again(x))\n",
    "data.loc[: 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for model: LogisticRegression is 0.8933738167529917\n",
      "Score for model: MultinomialNB is 0.7497767458474728\n",
      "Score for model: LinearSVC is 0.8873013038042508\n",
      "Score for model: SVC is 0.8962314699053402\n",
      "Score for model: RandomForestClassifier is 0.8231827111984283\n"
     ]
    }
   ],
   "source": [
    "# As I said above I will CountVectorizer as a transformator\n",
    "# I can also make it with TfidfVectorizer to compare it with results of CountVectorizer\n",
    "\n",
    "vector = CountVectorizer()\n",
    "x_vect = vector.fit_transform(data[\"Translated_Review\"])\n",
    "\n",
    "# After fitting data to CountVectorizer let's see what model will have best score out of all\n",
    "# But before that, we need to split data into train set and test set.\n",
    "# I wiil use a simple train_test_split method from sklearn.model_selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_vect, data[\"Sentiment\"], train_size=0.8, random_state=0)\n",
    "models = [LogisticRegression(), MultinomialNB(), LinearSVC(), SVC(kernel=\"linear\"), RandomForestClassifier()]\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Score for model: {} is {}\".format(model.__class__.__name__, model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22395, 17557) (5599, 17557)\n"
     ]
    }
   ],
   "source": [
    "# Not bad results. But let's first of all see the number of features of our reviews\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for model: LogisticRegression is 0.9021253795320593\n",
      "Score for model: MultinomialNB is 0.7490623325593856\n",
      "Score for model: LinearSVC is 0.906590462582604\n",
      "Score for model: SVC is 0.9076620825147348\n",
      "Score for model: RandomForestClassifier is 0.8528308626540454\n"
     ]
    }
   ],
   "source": [
    "# Wow. 18.5k features. Thats a big number. \n",
    "# Let's try to reduce the number of features using SelectPercentile and test it on models\n",
    "\n",
    "for model in models:\n",
    "    selector = SelectPercentile(percentile=5)\n",
    "    X_train_sel = selector.fit_transform(X_train, y_train)\n",
    "    X_test_sel = selector.transform(X_test)\n",
    "    model.fit(X_train_sel, y_train)\n",
    "    print(\"Score for model: {} is {}\".format(model.__class__.__name__, model.score(X_test_sel, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for model: LogisticRegression is 0.8622968387212002\n",
      "Score for model: MultinomialNB is 0.6906590462582604\n",
      "Score for model: LinearSVC is 0.8962314699053402\n",
      "Score for model: SVC is 0.8814073941775317\n",
      "Score for model: RandomForestClassifier is 0.8510448294338274\n"
     ]
    }
   ],
   "source": [
    "# Now it is better and also it reduces overall time of execution\n",
    "# Let's try it with TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "x_vect = tfidf_vect.fit_transform(data[\"Translated_Review\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_vect, data[\"Sentiment\"], train_size=0.8, random_state=0)\n",
    "for model in models:\n",
    "    selector = SelectPercentile(percentile=5)\n",
    "    X_train_sel = selector.fit_transform(X_train, y_train)\n",
    "    X_test_sel = selector.transform(X_test)\n",
    "    model.fit(X_train_sel, y_train)\n",
    "    print(\"Score for model: {} is {}\".format(model.__class__.__name__, model.score(X_test_sel, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfidfVectorizer a bit worst than CountVectorizer\n",
    "# Now let fine-tune model using GridSearchCV\n",
    "\n",
    "param_grid = {'C': np.arange(0.01, 100, 10)}\n",
    "linearSVC = GridSearchCV(LinearSVC(), param_grid, cv=5, return_train_score=True)\n",
    "linearSVC.fit(X_train, y_train)\n",
    "print(linearSVC.best_params_)\n",
    "\n",
    "bestlinearSVC = linearSVC.best_estimator_\n",
    "bestlinearSVC.fit(X_train,y_train)\n",
    "bestlinearSVC.coef_ = bestlinearSVC.named_steps['SVC'].coef_\n",
    "bestlinearSVC.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
